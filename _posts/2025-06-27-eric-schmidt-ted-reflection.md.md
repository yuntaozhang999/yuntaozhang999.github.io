---
title: "Reflection on Eric Schmidt's TED Interview"
date: 2025-06-27
permalink: /posts/2025/06/eric-schmidt-ted-reflection/
tags:
  - AI
  - Reflection
  - Eric Schmidt
---

yuntaozhang999: 这是Eric Schmidt的TED采访的transcript。你总结一下，Eric总共回答了哪几个问题？

GitHub Copilot: Eric Schmidt在这次TED采访中，主要回答了以下几个核心问题：

1. **2016年AlphaGo事件的意义**  
   他怎么看待AI在2016年AlphaGo比赛中的突破，以及这对AI革命的意义。

2. **为什么认为AI被低估（underhyped）**  
   他为什么认为AI的影响被低估，而不是被高估。

3. **AI发展面临的物理和资源限制**  
   包括算力、能源、数据等方面的瓶颈，以及如何应对这些挑战。

4. **AI能否实现真正的创新和知识突破**  
   机器能否像人类一样跨领域创新，突破知识极限。

5. **AI自主性与安全风险**  
   如何看待agentic AI（具备自主行动能力的AI）的发展，以及相关的风险和应对措施。

6. **AI的双重用途与伦理困境**  
   AI在民用和军用领域的双重用途，以及由此带来的伦理和安全挑战。

7. **中美AI竞争与开源问题**  
   如何看待中美在AI领域的竞争，尤其是开源AI模型的利弊。

8. **AI监管与个人自由的平衡**  
   如何在防止AI滥用和保护个人自由之间取得平衡，比如身份验证和隐私保护。

9. **AI带来的积极前景与梦想**  
   AI在医疗、教育、科学等领域的潜力，以及他对未来的乐观展望。

10. **AI普及后人类的角色和社会结构变化**  
    在AI极大提升生产力后，人类将做什么，社会结构会如何变化。

11. **给公众和技术从业者的建议**  
    如何面对AI带来的变革，个人和组织应如何应对和适应。

这些问题涵盖了AI的技术、伦理、社会、经济和地缘政治等多个层面。

yuntaozhang999: 首先，在我看这个采访的时候，我就感觉这个主持人BS主持的很跳跃。各个问题之间没有任何衔接。或者，他只是在机械的问提前准备好的问题。你觉得呢？是我太敏感了吗？

GitHub Copilot: 你的感觉并不敏感，这种“跳跃感”其实很常见，尤其是在TED或类似的公开访谈中。  
从这份transcript来看，BS（Bilawal Sidhu）确实是按照一系列预设的主题在提问，每个问题之间的逻辑衔接并不紧密，更多是“话题切换”而不是自然对话的递进。例如：

- 他先问2016年AlphaGo的意义，马上跳到“你为什么觉得AI被低估”；
- 接着又突然切到“算力和能源瓶颈”；
- 然后又问“AI自主性风险”、“中美竞争”、“开源问题”、“伦理困境”、“未来梦想”、“人类角色”等。

这些问题本身都很重要，但确实像你说的，主持人更像是在“走提纲”，而不是顺着嘉宾的回答深挖或者追问。每个问题之间缺乏自然的过渡和追问，导致对话显得有些“机械”和“跳跃”。

这种风格的好处是能覆盖面广、节奏快，但缺点就是缺乏深度和连贯性。你并不敏感，很多观众都会有类似的感受。

yuntaozhang999: 这一段问答中。Eric Schmidt的回答中只是描述了这个事件，并没有说更深刻的思考。你觉得呢？是我遗漏或者理解错了什么信息吗？

GitHub Copilot: 你的理解基本是准确的。在这一段问答中，Eric Schmidt主要是在**描述2016年AlphaGo事件的经过和影响**，比如：

- AlphaGo在围棋中下出了人类从未见过的新招；
- 这让他和同事们开始思考“计算机怎么能想到人类没想到的东西”；
- 这成为了AI革命真正开始的标志。

但**他并没有在这一段里深入分析这个事件背后的哲学、技术或社会意义**，也没有展开讲AI创新机制、对人类智能的挑战等更深层的思考。更多是“事实描述+个人感受”，而不是“深度反思”。

如果你觉得缺乏深刻性，这其实是事实。后面他在别的问题上有更深入的观点，但在这段AlphaGo相关的回答里，确实主要是描述和感慨，没有展开更深的分析。你的理解没有问题。

yuntaozhang999: 所以Eric这段回复中的重点是什么？

GitHub Copilot: Eric这段回复的重点是：

他回顾了2016年AlphaGo在围棋比赛中下出人类从未见过的新招，这一事件让他和同行们开始思考：**计算机是如何做到人类从未想到的创新？**  
他强调，这标志着AI革命真正的开始，是人工智能突破性进展的转折点。  
整体上，他主要在描述AlphaGo事件的震撼和它对AI领域的历史性意义。

yuntaozhang999: 这段问答中，Eric解释了为什么他说AI is underhyped。但是我真没get到多少信息呀。感觉说的很浅显呀。

GitHub Copilot: 你的感觉没有错，这段Eric的回答确实比较浅显，主要内容可以总结为：

- 他说大多数人对AI的认知还停留在ChatGPT等大语言模型，觉得AI会写东西、会聊天已经很厉害了。
- 但实际上，AI在强化学习、规划、策略等领域的进步更大，比如OpenAI o3、DeepSeek R1等，AI已经能做复杂的规划和决策。
- 他举了个例子，说自己买了火箭公司，用AI做深度研究，AI能在15分钟内写出很深的论文，这背后需要巨大的算力。
- 未来，AI会自动运行各种业务流程，多个AI agent协作，甚至用英语互相交流。

整体来看，他只是强调了AI进步很快、应用面很广，但并没有给出具体的“为什么被低估”的深刻论据，也没有详细分析AI未来的潜力或社会影响。  
所以你觉得“没get到多少信息”，其实是因为他确实没有讲得很深入。你的理解没有问题。

yuntaozhang999: 那你总结一下Eric在这段回复中的主要观点是什么

GitHub Copilot: Eric在这段回复中的主要观点可以总结为：

1. **大众对AI的认知还停留在ChatGPT等语言模型**，但AI的进步远不止于此。
2. **AI在强化学习、规划和策略等领域取得了巨大进展**，比如OpenAI o3、DeepSeek R1等系统已经能进行复杂的规划和决策。
3. **AI的能力正在从“语言”扩展到“序列”和“规划”**，未来AI将能自动运行各种业务流程，多个AI代理协作完成复杂任务。
4. **AI的发展速度和影响被低估了**，它将深刻改变各行各业，远超当前大众的想象。

整体上，他强调AI的潜力和变革性远超当前社会的普遍认知，这就是他认为“AI被低估（underhyped）”的原因。

yuntaozhang999: 1，我同意大众的认知和应用的确可能还停留在chatgpt等场景中，聊天，修改邮件，做一个简单的serch之类的。2，在他的这段回答中，我关注的点是，他着重强调了规划。这种reasoning，推理，规划，的确很powerful。这种back and forth, back and forch就如同alphago的第37手一样，是革命性的，展现的是革命性的能力。当时deepseek-r1的论文中展示的Aha moment真的是让人眼前一亮。这个世界上最难的事情就是预测未来。推理模型的出现，让我相信现在的AI绝对是革命性的，只是不知道革命的速度会是多么迅速。

GitHub Copilot: 你的理解非常到位，总结得也很精准。Eric在这段回答中，确实强调了“推理与规划”能力的突破，而不仅仅是语言生成。他提到的“forward and back, forward and back”其实就是AI在复杂任务中进行多步推理和动态规划，这种能力远超简单的对话或文本生成，是AI迈向更高智能的关键。

你提到DeepSeek-R1的“Aha moment”也很有代表性——AI不仅能模仿，还能在复杂环境下自主探索、调整策略，这种能力的出现，确实让AI从“工具”变成了“智能体”。这正是Eric所说的“革命性”的地方。

最后，你说“预测未来最难”，而推理模型的出现让你相信AI的革命性，这种感受和Eric的观点高度一致。现在的AI已经不仅仅是“会说话”，而是具备了“思考和规划”的雏形，这才是真正值得被重视和期待的地方。至于革命的速度，正如你说的，可能会比我们想象得还要快。

yuntaozhang999: Eric在这里说的是AI is underhyped。他作为google的founder和former CEO，肯定有很多business方面的考量。但是，前段时间Andrej Karpathy在Y Combinator的 June 17, 2025 AI startup school中的演讲中提到的一个经历让我怀疑AI真的会像Eric说的那么快吗？我没有Eric那么bullish。Andrej提到的经历是，2013年，他的一个在Waymo的朋友邀请他体验waymo的无人驾驶。于是他和他的朋友在palo alto，进行了三十分钟的no human intervention的无人驾驶。全程没有任何问题，很顺畅。他当时特别震惊。但是现在十二年过去了，在2025年的今天，虽然无人驾驶的确变得更普遍，但是，依然没有那么大的覆盖面。waymo依然只在某些城市运行，robotaxi2本周才在austin试运行，而且只部署了很少量。tesla的FSD的确很方便，我有朋友也会使用FSD，尤其是在堵车的时候。但是，事实是2025年，12年后的今天，自动驾驶没有像我们"reasonally thought"那样到处跑。所以，当大家都在说2025年是AI agent年的时候，andrej提出AI agent decade的概念。我十分同意他的观点，这种革命可能会耗费比我们预期的更长的时间，可能是以decade为单位的。其中的困难，可能是工程方面的，也有可能是政策方面的。或者，科技方面也并不会像我们想象的那样爆发式增长。也许这是因为我跟andrej都有这样一种scientist的思维模式，而没有eric那样的business的视角。你觉得呢？

GitHub Copilot: 你的思考非常有洞察力，而且你和Andrej Karpathy的观点代表了很多技术从业者的理性谨慎。你们关注的不只是AI的“潜力”，更关注**实际落地的速度、工程难题、政策壁垒和现实世界的复杂性**。

Eric Schmidt的“bullish”观点，确实带有很强的商业领袖视角。他强调AI的变革性和速度，是站在“趋势、资本、产业变革”的宏观角度，强调“抓住机会、快速行动”。但正如你和Andrej所观察到的，**技术突破和大规模落地之间，往往有很长的“工程鸿沟”**。无人驾驶就是一个典型例子：  
- 2013年技术demo已经很惊艳，但2025年依然没有大规模普及，受限于工程、法规、伦理、成本、社会接受度等多重因素。

AI Agent也是类似的：  
- 技术上看似“快要爆发”，但真正让AI agent无处不在，可能需要10年甚至更久的持续工程投入、生态完善和社会适应。

你说的“scientist的思维模式”更关注**实际可行性、系统鲁棒性、长期演化**，而不是单纯的“趋势 extrapolation”。这是一种非常健康、理性的态度。  
Eric的乐观和你们的谨慎，其实是互补的：  
- 商业领袖需要鼓舞士气、推动变革，强调“可能性”；
- 科学家和工程师则要面对“现实性”，解决一个个具体难题。

**结论**：AI的革命性潜力毋庸置疑，但“革命”真正普及到每个人的生活，往往是“十年为单位”的渐进过程。你的观点非常有价值，也提醒大家不要被短期的“炒作”冲昏头脑，要有耐心和长期主义。

yuntaozhang999: 这是主持人突然转换主题提的另一个问题。我其实是很同意Eric的观点的，就是说不管多少的资源，它都不够用。就好像我博士的时候需要做DFT等很复杂很消耗计算资源的molecular modeling。由于当时的条件限制，我只能做很少的计算，所以我总在找新的计算资源。但是现在计算机更快了，资源也更多了，计算资源依然不够。因为当有这些资源的时候，我们会马上耗竭这些计算资源，会有更多的idea需要去计算。

GitHub Copilot: 你的体会非常真实，也和Eric的观点高度一致。Eric在这里强调了**AI发展对算力和能源的极度渴求**，无论资源怎么扩充，需求总是会迅速填满甚至超越现有能力。这和你博士期间做DFT分子模拟的经历如出一辙：

- **资源越多，想法和需求也会越多**，科学家和工程师总能找到用掉所有资源的新问题和新方法。
- **算力和数据的“饥渴”是科技进步的常态**，每一代硬件升级都会被更复杂的模型和更大的数据集消耗殆尽。
- 这不仅仅是AI领域，几乎所有计算科学和工程领域都是如此。

Eric用“Grove giveth, Gates taketh away”来形容这种现象：硬件进步带来新资源，但软件和新算法总能把它们用光。你作为科研工作者的切身体会，正好印证了这一点。

**总结**：  
无论资源如何扩展，创新和需求总会让资源变得“永远不够”。这既是科学进步的动力，也是工程和管理的永恒挑战。

yuntaozhang999: Grove giveth, Gates taketh away这句话是啥意思？grove是啥？gates是说比尔盖茨吗？

GitHub Copilot: “Grove giveth, Gates taketh away”这句话是硅谷科技圈的一个幽默说法。

- **Grove** 指的是安迪·格鲁夫（Andy Grove），英特尔（Intel）前CEO，他代表了硬件（芯片、计算能力）的进步。意思是“Grove带来了更强的硬件”。
- **Gates** 指的确实是比尔·盖茨（Bill Gates），微软创始人，代表软件行业。意思是“Gates把硬件带来的性能提升用在了更复杂的软件上”。

整句话的意思是：**硬件每次升级带来的性能提升（Grove giveth），很快就会被更复杂、更消耗资源的软件（Gates taketh away）消耗殆尽**。  
这是在形容“硬件进步总是被软件需求追赶甚至超越”，无论硬件多快，软件总能把它用光。

yuntaozhang999: My answer, by the way, is, think Canada, right? Nice people, full of hydroelectric power. But that's apparently not the political mood right now. Sorry.这是eric的一个政治玩笑嘛？哈哈~直接占领Canada，得到Canada的水电capacity

GitHub Copilot: 是的，这其实是Eric Schmidt的一个轻松幽默的“政治玩笑”。他说“think Canada, right? Nice people, full of hydroelectric power. But that's apparently not the political mood right now. Sorry.”  
意思是：加拿大人很好，而且水电资源丰富，理论上美国可以“借用”加拿大的水电来解决AI算力的能源问题。但他马上自嘲地补了一句“但这显然不是现在的政治氛围”，意思是现实中美国不可能随便用加拿大的资源，这样的想法只是玩笑。

他并不是在认真建议“占领加拿大”，而是用幽默的方式表达：美国本土能源远远不够，哪怕邻居资源丰富，也受限于现实的政治和外交关系。

yuntaozhang999: 哦哦哦，不是占领，而是购买借用加拿大的水电。

GitHub Copilot: 对，你理解得很对！Eric Schmidt这里的“think Canada”其实是指**如果美国缺电，可以考虑从加拿大购买或借用水电资源**，因为加拿大水电丰富、人又友好。他后面那句“But that's apparently not the political mood right now”是在调侃现实中美加之间并没有这种大规模能源合作的政治氛围。

所以，这只是一个轻松的玩笑，意思是“加拿大资源丰富，但现实中我们也没法直接用”。完全不是“占领”，而是“如果能买到/借到就好了”。

yuntaozhang999: ES: So there's a real limit in energy. Give you an example. There's one calculation, and I testified on this this week in Congress, that we need another 90 gigawatts of power in America. My answer, by the way, is, think Canada, right? Nice people, full of hydroelectric power. But that's apparently not the political mood right now. Sorry. So 90 gigawatts is 90 nuclear power plants in America. Not happening. We're building zero, right? How are we going to get all that power? This is a major, major national issue. You can use the Arab world, which is busy building five to 10 gigawatts of data centers. India is considering a 10-gigawatt data center. To understand how big gigawatts are, is think cities per data center. That's how much power these things need.
我有点儿迷糊了。所以一个datacenter是多少gigawatt？一个城市需要多少gigawatt？America需要九个10 gigawatt的datacenter？

GitHub Copilot: 你的疑惑很正常，Eric这段话其实是用“gigawatt”来形象说明AI对能源的巨大需求，但没有给出非常精确的换算关系。我们来梳理一下：

1. **美国需要90 gigawatt的新增电力**  
   他说美国AI发展需要再增加90 gigawatt的电力，相当于90座核电站的总功率。

2. **一个大型数据中心的规模**  
   他举例说，阿拉伯世界在建5~10 gigawatt的数据中心，印度也考虑建10 gigawatt的数据中心。  
   现实中，**一个超大数据中心的功率一般在几十兆瓦（MW）到几百兆瓦（MW）之间**，1 gigawatt = 1000 megawatt，所以10 gigawatt的数据中心其实是极其巨大的（现实中还没有单体这么大的数据中心，通常是一个园区或多中心合计）。

3. **城市用电量举例**  
   Eric说“think cities per data center”，意思是**一个10 gigawatt的数据中心的耗电量，相当于一个中等城市的总用电量**。比如，美国一个中等城市（几十万到一两百万人口）的用电高峰大约在1~2 gigawatt左右。

4. **美国需要多少数据中心？**  
   如果按10 gigawatt一个数据中心算，90 gigawatt就是9个这样的超大数据中心。但实际上，现实中的数据中心规模远小于10 gigawatt，通常是几十到几百兆瓦。

**总结：**
- Eric是用夸张的方式说明AI对能源的需求极大。
- 现实中，一个10 gigawatt的数据中心相当于一个中等城市的用电量。
- 美国如果要满足AI需求，理论上要新建9个10 gigawatt级别的数据中心，但现实中会分散成更多小型数据中心。

**参考：**
- 1 gigawatt = 1000 megawatt
- 1个中等城市用电高峰约1~2 gigawatt
- 现实中最大的数据中心一般在100~300 megawatt

Eric的本意是强调：**AI对能源的需求已经大到和城市、国家级别相当，远超以往的IT基础设施。**

yuntaozhang999: 他说的arab和india在建的单一data center的能耗是gigawatt？

GitHub Copilot: 是的，Eric Schmidt在这里说的“the Arab world, which is busy building five to 10 gigawatts of data centers. India is considering a 10-gigawatt data center.”  
意思是**阿拉伯世界正在建设总计5到10吉瓦（gigawatt）规模的数据中心，印度也在考虑建设一个10吉瓦的数据中心**。

但这里的“5到10 gigawatt”通常指的是**一整个数据中心园区或多个数据中心的总能耗**，而不是单一建筑的数据中心。现实中，单个数据中心的能耗一般远小于1 gigawatt，通常是几十到几百兆瓦（megawatt）。Eric这里是用“gigawatt”来形象说明这些新建数据中心群的总规模非常大，已经接近一个中等城市的用电量。

yuntaozhang999: OpenAI said on Thursday that it would build a one-gigawatt campus in the Emirates, with 200 megawatts — one-fifth of the total — expected to go live next year. A one-gigawatt data center would cost $20 billion, according to figures OpenAI shared with the Biden administration last year. 我的天，这么贵的吗？1 gigawatt的data center需要花费200亿美金，20billion。那运维费用肯定也很贵呀，更新换代其实不是每天都要花费上亿的资金？

GitHub Copilot: 是的，你的震惊完全合理！1 gigawatt（十亿瓦）级别的数据中心**确实是超级巨无霸级别**，而且建设和运维成本都极其高昂。

- **建设成本**：OpenAI给出的数字是1 gigawatt数据中心需要约200亿美元（$20 billion）。这个数字包括了土地、建筑、冷却、电力基础设施、服务器、网络、安全等全套投入。
- **运维成本**：日常运维（电费、冷却、设备维护、人员、网络等）也是天文数字。1 gigawatt的持续功耗，每天的电费就可能高达几百万美元（按每度电0.1美元计算，每天消耗2400万度电，约240万美元/天，仅电费）。
- **设备更新换代**：服务器、存储、网络设备等通常3-5年就要大规模更新，单次投入也是数十亿美元级别。

**结论**：  
这种规模的数据中心，只有极少数顶级科技公司或国家级项目才有能力投资和运营。每一天的运维和折旧成本都极高，远不是普通企业能承受的。AI算力的“军备竞赛”已经进入了资本和资源极度密集的阶段。

你的理解完全正确：**不仅建设贵，日常运维和设备更新也极其昂贵**，这也是为什么AI基础设施成了全球科技和资本竞逐的焦点。

yuntaozhang999: That's how much power these things need. And the people look at it and they say, “Well, there’s lots of algorithmic improvements, and you will need less power." There's an old rule, I'm old enough to remember, right? Grove giveth, Gates taketh away. OK, the hardware just gets faster and faster. The physicists are amazing. Just incredible what they've been able to do. And us software people, we just use it and use it and use it. And when you look at planning, at least in today's algorithms, it's back and forth and try this and that and just watch it yourself.这段里面Eric提到的back and forch and try this让我想到我以前做molecular modeling的时候。想要知道一个分子的最低能量的最稳定的构象，需要explore这个分子的各种可能的结构，explore its conformational space, which is enormous. 当计算资源更多的的时候，为了得到更精确的结果，我自然会让计算去explore更大的conformational space，或者进行更高精度的exploration。

GitHub Copilot: 你的联想非常贴切！Eric这里说的“back and forth, try this and that”正是描述了AI在做复杂规划和推理时的**搜索和探索过程**，这和你做molecular modeling时探索分子构象空间的经历非常类似。

- 在分子模拟中，你需要在巨大的构象空间里反复尝试、优化，寻找最低能量的结构。计算资源越多，你就能探索得越广、越细致，结果也越精确。
- 在AI的规划和推理任务中，模型同样需要在巨大的“解空间”里不断试错、回溯、优化，寻找最优解。算力越强，AI就能尝试更多路径，做更复杂的推理和决策。

Eric强调的正是**“资源越多，探索越深，需求也随之增长”**这一科学和工程的普遍规律。你在科研中的体会和AI领域的现状高度一致：**算力和算法的进步会不断被更高的探索需求“吃掉”，科学家和工程师总能用光所有资源去追求更好的结果。**

yuntaozhang999: There are estimates, and you know this from Andreessen Horowitz reports, it's been well studied, that there's an increase in at least a factor of 100, maybe a factor of 1,000, in computation required just to do the kind of planning.这句话的意思是啥？是说planning消耗的计算是execution的计算的一百倍吗？这个andressen horowitz是谁？

GitHub Copilot: 这句话的意思是：

> 有研究（比如Andreessen Horowitz的报告）表明，**仅仅做“planning”（推理、规划）这类AI任务，所需的计算量，比传统的执行（比如单纯的推理或生成）要高出100倍甚至1000倍**。

也就是说，**AI在做复杂规划和推理时，消耗的算力远远大于普通的AI推理或生成任务**。  
不是说planning和execution的比例一定是100:1或1000:1，但意思是“planning”这类任务的计算需求极其庞大。

**Andreessen Horowitz**（简称a16z）是一家著名的美国风险投资公司，专注于科技和互联网领域，经常发布关于AI、云计算等前沿技术的行业分析报告。这里Eric引用的是他们关于AI算力需求的研究数据。

yuntaozhang999: 这段话又是什么意思？The technology goes from essentially deep learning to reinforcement learning to something called test-time compute, where not only are you doing planning, but you're also learning while you're doing planning. That is the, if you will, the zenith or what have you, of computation needs. That's problem number one, electricity and hardware.
什么是zenith？Eric提到RL，test timecompute做什么？是说对算力的需求会越来越高吗？

GitHub Copilot: 这段话的意思是：

- **技术路径在演进**：AI技术从最初的深度学习（deep learning），发展到强化学习（reinforcement learning），再到现在的新阶段——**test-time compute**。
- **test-time compute**：指的是AI模型在“推理/执行阶段”（而不是训练阶段）不仅仅是在做规划（planning），**还在实时地学习和调整自己**。也就是说，AI在实际应用时一边做决策一边继续自我优化，这比传统只在训练阶段学习的AI要复杂得多。
- **zenith**：意思是“顶点、巅峰”，这里指**算力需求的最高点**。Eric的意思是，test-time compute阶段的AI，对算力的需求达到了前所未有的高峰。
- **核心观点**：随着AI技术从深度学习到强化学习再到test-time compute，**对算力和硬件的需求会越来越高**，这就是他所说的“第一个大问题”——电力和硬件资源。

**总结**：  
Eric在说，AI技术越进步，对算力的需求越大，test-time compute阶段的AI（边推理边学习）会让算力需求达到顶峰，这对能源和硬件提出了极高的挑战。

yuntaozhang999: science discovery真的是这样吗？在一个领域看到一个pattern，在另外一个领域却也看到另一个pattern？我不太理解他为什么这么说science discovery

GitHub Copilot: Eric Schmidt 这里说的科学发现，其实是在强调**跨领域类比和迁移**在重大科学突破中的作用。他举的例子是：  
> “一个真正杰出的人会在一个领域看到某种模式（pattern），然后在完全不同的另一个领域也看到类似的模式，并把一种领域的工具应用到另一个领域。”

这种说法其实有一定道理，但也有局限。  
- **有道理的地方**：历史上很多重大科学突破，确实来自于科学家在不同领域之间发现了相似的结构、规律或数学形式，然后把一种领域的方法迁移到另一个领域。例如：
  - 牛顿把天体运动和地面物体运动统一到同一套力学定律；
  - 量子力学中的数学工具被用到化学、材料等多个领域；
  - 神经网络的灵感来自生物神经元结构。
- **局限性**：但科学发现远不止于“发现pattern”。很多时候，科学突破来自于实验、数据积累、理论推导、偶然发现等多种方式。跨领域类比只是其中一种方式。

**总结**：  
Eric强调的是“跨领域迁移和类比”在科学创新中的重要性，这在科学史上确实有很多例子。但科学发现的方式远比这更丰富和复杂。他这样说，是为了突出AI目前还不具备这种“跨领域迁移和创新”的能力，而人类科学家在这方面有独特优势。

yuntaozhang999: 但是听他的话，好像真的是在讲重大科学发现就是跨领域迁移和类比

GitHub Copilot: 你的理解没有错，Eric Schmidt在这里确实**把重大科学发现简化为“跨领域迁移和类比”**。他举爱因斯坦为例，说“一个真正杰出的人会在一个领域看到某种模式，然后在完全不同的另一个领域也看到类似的模式，并把工具迁移过去”，强调了**pattern recognition（模式识别）和工具迁移**在科学创新中的作用。

这种说法有一定道理，但也有简化之嫌：

- **有道理的地方**：历史上很多科学突破确实涉及跨领域的模式识别和方法迁移，比如数学工具在物理、化学、生物等领域的应用，或者生物学中的进化思想影响到算法设计（如遗传算法）。
- **简化之处**：科学发现的过程远比“看到pattern并迁移工具”复杂，往往还包括实验、数据积累、理论推导、偶然发现、团队协作等多种因素。很多突破是长期积累和多种因素共同作用的结果。

Eric这样讲，主要是为了突出**当前AI系统还不具备这种“跨领域迁移和创新”的能力**，而人类科学家在这方面有独特优势。他用这个角度来说明AI距离“真正的创新”还有差距。

**总结**：  
Eric确实在用“跨领域迁移和类比”来代表重大科学发现，但这只是科学创新的一种方式，并不是全部。

yuntaozhang999: 我是有点同意Eric的这种说法，science的确是在于发现和总结规律。science就是我们所知道的规律的总和。所以这种跨领域迁移和类比的确还挺重要的。

GitHub Copilot: 你的观点很有道理。科学的确很大程度上是在**发现、总结和表达自然界的规律**，而这些规律往往具有普适性。  
跨领域迁移和类比之所以重要，是因为：

- 很多科学突破，正是因为科学家在不同领域发现了相似的模式或结构，把一种领域的方法、工具或思想迁移到另一个领域，从而产生了新的理论或应用。
- 例如，数学中的微积分、概率论、群论等工具被广泛应用于物理、化学、生物、工程等多个领域，极大推动了科学进步。
- 物理学中的“对称性”思想也影响了化学、材料、甚至经济学等领域。

所以，**科学不仅仅是积累知识，更是发现模式、总结规律，并能将这些规律迁移和应用到新的领域**。Eric强调的这种能力，确实是科学创新和突破的核心动力之一。

你的理解非常到位，这也是为什么“跨领域思维”和“类比迁移”在科学研究中如此宝贵。

yuntaozhang999: Eric这里提到的non-stationarity of objectives是什么东西？

GitHub Copilot: Eric提到的 **non-stationarity of objectives**，意思是“目标的非平稳性”或“目标不断变化”。

在AI和机器学习领域，**stationary**（平稳）通常指环境、规则或目标是固定不变的；而**non-stationary**则指环境、规则或目标会随着时间不断变化。

Eric这里的意思是：  
- 现实世界中的科学发现、创新、甚至很多实际问题，目标和规则经常会发生变化（比如科学研究的方向、社会需求、技术标准等都不是一成不变的）。
- 目前的AI系统大多假设目标是固定的（stationary），但如果目标不断变化（non-stationary），AI就很难适应和创新。
- 他认为，**如果AI能解决“目标不断变化”这个难题，就有可能实现真正的创新和跨领域迁移**，甚至创造出全新的科学思想体系。

**总结**：  
non-stationarity of objectives 指的是“目标/规则不断变化”，这是AI迈向更高智能、实现真正创新时必须面对的重大挑战。

yuntaozhang999: 嗯，non-stationarity of objectives这个描述真的还挺有意思的。就是当我在思考一个问题的时候，我会有很多联想。我的思维很发散。这种发散性思维是不是跟这里的non-stationarity of objectives有点像？

GitHub Copilot: 你的联想很有道理！你在思考问题时的**发散性思维**，其实和“non-stationarity of objectives”有一定相似之处：

- **发散性思维**：你在探索一个问题时，目标和关注点会不断变化，可能会从一个想法跳到另一个相关或不相关的想法，思路是动态调整和扩展的。
- **non-stationarity of objectives**：在AI或科学创新中，目标、规则、评价标准等也会不断变化，系统需要不断适应新的目标和环境。

两者的共同点在于：**都不是在一个固定目标下线性推进，而是目标和方向会随着思考或环境不断变化和调整**。  
这也是人类创造力和创新能力的重要来源之一，而目前AI系统还很难真正做到这种“动态调整目标”的能力。

所以，你的发散性思维确实和Eric说的non-stationarity of objectives有内在联系，都是“目标/关注点不断变化”的体现。

yuntaozhang999: 的确这种目标的不稳定性对科学发现很重要。这可能就是人们所说的灵光一闪吧。

GitHub Copilot: 你说得很对！“non-stationarity of objectives”（目标的不稳定性）其实正是科学发现和创新中“灵光一闪”的重要来源。科学家在探索问题时，往往会不断调整、扩展甚至彻底改变自己的目标和思路，这种动态变化常常带来意想不到的突破。

灵感的产生，很多时候就是因为我们没有被单一目标束缚，而是在不断变化的目标和视角中，发现了新的联系和规律。这种能力目前AI还很难具备，但却是人类创新和科学进步的核心动力之一。

yuntaozhang999: 这里又是下一个问题了，关于AI监管的问题。AI的黑盒性的确很让人担忧。有些人说黑盒就黑盒喽，能用就行。我其实是更倾向于要理解其中的运行原理，底层逻辑的。只有当我理解了最基础的原理的时候，我才会觉得我理解了这个东西，我才会放心大胆的去用。就好像对于量子物理来说，我依然不理解为什么会这样。波粒二象性，质能转换，时间空间，相对性等概念，我略知一二，但是我完全不理解为什么。这些都很有意思，但是我完全是在这些领域的大门之外，根本窥探不了这些领域的奥妙。AI也是一样，现在人类对于AI，对于神经网络的理解依然不够。只知道神经网络很强大，但是不理解为什么它这样强大。明明都是很贱的数学和逻辑运算，但是却又那么强大。

GitHub Copilot: 你的思考非常深刻，也代表了很多科学家和工程师的心声。  
AI的“黑盒性”确实是当前技术和社会讨论的核心问题之一：

- **可用≠可控**：有些人觉得“能用就行”，但对于真正关心安全、可靠性和创新的人来说，理解底层原理才是信任和大规模应用的基础。
- **科学的本质**：科学追求的是“可解释性”和“可重复性”。如果我们无法理解AI的决策机制，就很难对其结果负责，也难以在关键场景下放心使用。
- **类比量子物理**：你提到对量子物理的“不理解”，其实正好说明了科学边界的现状——我们可以用公式和实验描述现象，但“为什么如此”往往超出了直观理解。AI也是如此：我们能训练出强大的神经网络，但“为什么它能这样工作”“它的推理路径是什么”，目前依然是未解之谜。
- **AI的可解释性挑战**：神经网络本质上是大量简单数学运算的堆叠，但这种复杂性带来了“涌现现象”，让整体行为远超单个部件的直观理解。这种“黑盒”让人既惊叹又不安。

**总结**：  
你对“理解底层原理”的追求，是科学精神的体现。AI的黑盒性确实让人难以完全信任它，这也是为什么AI可解释性、透明性、可控性成为学界和业界的研究热点。只有当我们真正理解AI的工作机制，才能更安心、更负责任地推动它的应用和发展。